{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ddc016dc-19da-4a7f-a4fa-dd303e5b5a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80dff874-39af-4eca-81d8-d43fa89de1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onefile_importer(fname,\n",
    "                     sheet_json,\n",
    "                     sample_info,\n",
    "                     metab_json,\n",
    "                     average_blanks=False,\n",
    "                     zero_negatives=True,\n",
    "                     plate_flip=False):\n",
    "    '''\n",
    "    Importer to convert EcoPlate data in Excel format to a tidy DataFrame.\n",
    "\n",
    "    Params\n",
    "    ______\n",
    "\n",
    "    fname : str\n",
    "        Path to an Excel file containing  EcoPlate data. The title of the files\n",
    "        should be \"[timepoint]h_[anyOtherInfo].xlsx\". For example, \n",
    "        \"24h_winter2025.xlsx\". The function expects that every Excel file \n",
    "        represents a timepoint, and every sheet within the file represents a \n",
    "        plate. Plate data should be exported such that somewhere in the sheet is \n",
    "        a table with the columns \"Well\" (containing the well numbers) and \"590\" \n",
    "        (containing the absorbance values). It is not critical on which line the \n",
    "        table starts; the function will attempt to find a line that matches this\n",
    "        format.\n",
    "\n",
    "    sheet_json : str\n",
    "        Path to a JSON file containing sample information for each sheet. The keys of \n",
    "        the JSON should be the sheet names (e.g., \"Plate 1 - Sheet1\") and the values\n",
    "        should be the sample name (e.g., \"25D_W_1\"). If the sample name contains\n",
    "        multiple pieces of relevant information (in this case condition, water/larvae,\n",
    "        and replicate), the pieces should be separated by underscores. There are no limits\n",
    "        on the amount of information you can store in the sample name, but all sample names\n",
    "        must contain the same number of underscores.\n",
    "\n",
    "    sample_info : tuple or None\n",
    "        A tuple containing the desired column names for infomation derived from sample\n",
    "        names. For samples with the format \"25D_W_1\", sample_info might be (\"diapause\",\n",
    "        \"water\",\"replicate\"). If None, the columns will be named \"s1\", \"s2\", etc.\n",
    "\n",
    "    metab_json : str\n",
    "        Path to a JSON file in which keys are the plate well positions and values are the \n",
    "        metabolites. The JSON provided in the \"resources\" folder of this repo is derived\n",
    "        from this file: \n",
    "        https://www.biolog.com/wp-content/uploads/2023/08/00A-012-Rev-F-EcoPlate-IFU.pdf\n",
    "\n",
    "    average_blanks : Bool\n",
    "        If True, all Water well 590 values will be averaged and used as the blank for the \n",
    "        entire plate. If False, the A1 Water well will be used to blank columns 1-4, A5 \n",
    "        for columns 5-8, and A9 for columns 9-12. Default: False\n",
    "    \n",
    "    zero_negatives : Bool\n",
    "        If True, any blanked 590 absorbance values below zero will instead be set to zero/\n",
    "        If False, negative values will remain negative. Default: True\n",
    "\n",
    "    plate_flip : Bool\n",
    "        Set to True if the plate was read such that H12 was accidentally put in the A1\n",
    "        position. The function will remap all of the values to the correct wells before\n",
    "        labeling metabolites.\n",
    "\n",
    "    Output\n",
    "    ______\n",
    "\n",
    "    A Pandas DataFrame containing columns for well, metabolite, raw 590 value, blanked\n",
    "    590 value, and any sample information.     \n",
    "    \n",
    "    '''\n",
    "    # Get sample ID and metabolite info\n",
    "    with open(sheet_json,'r') as f:\n",
    "        pid = json.load(f)\n",
    "\n",
    "    with open(metab_json,'r') as f:\n",
    "        eco = json.load(f)\n",
    "\n",
    "    # Identify blank wells\n",
    "    water = [k for k,v in eco.items() if v == 'Water']\n",
    "\n",
    "    # Get sheets\n",
    "    sheets = pd.ExcelFile(fname).sheet_names\n",
    "\n",
    "    # Extract data for each sheet\n",
    "    df_ls = []\n",
    "    for s in sheets:\n",
    "        # Identify header row to get number of rows to skip\n",
    "        df = pd.read_excel(fname,\n",
    "                           sheet_name=s)\n",
    "        skiprows = None\n",
    "        for i in df.index:\n",
    "            if 'Well' in list(df.loc[i,:]):\n",
    "                skiprows=i+1\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        # Verify that header was identified, otherwise raise an error\n",
    "        try:\n",
    "            int(skiprows)\n",
    "        except:\n",
    "            raise Exception('Header row not found for '+sheet_name)\n",
    "\n",
    "        # Import tidy data\n",
    "        df = pd.read_excel('exampleData/24h_example.xlsx',\n",
    "                   sheet_name=s,\n",
    "                   skiprows=skiprows)\n",
    "        df = df.dropna(axis=1)\n",
    "        df.columns = [str(i) for i in df.columns]\n",
    "\n",
    "        # Correct plate flipping\n",
    "        if plate_flip:\n",
    "            orig_rows = [chr(65+i) for i in range(8)]\n",
    "            orig_cols = [str(i) for i in np.arange(1,13)]\n",
    "            \n",
    "            df['orig_row'] = [i[0] for i in df['Well']]\n",
    "            df['orig_col'] = [i[1:] for i in df['Well']]\n",
    "            \n",
    "            df['new_row'] = [orig_rows[::-1][orig_rows.index(r)] for r in df['orig_row']]\n",
    "            df['new_col'] = [orig_cols[::-1][orig_cols.index(r)] for r in df['orig_col']]\n",
    "            \n",
    "            df['Well'] = df['new_row'] + df['new_col']\n",
    "            df = df.drop(['orig_row','orig_col','new_row','new_col'], axis=1)\n",
    "        else:\n",
    "            pass \n",
    "\n",
    "        # Add metabolites\n",
    "        df['metab'] = [eco[i] for i in df['Well']]\n",
    "\n",
    "        # Add timepoints\n",
    "        basename = fname.split('/')[-1]\n",
    "        timepoint = basename.split('_')[0]\n",
    "        df['timepoint'] = [timepoint for i in df.index]\n",
    "\n",
    "        # Add sample information\n",
    "        subdict = pid[timepoint]\n",
    "        sample = subdict[s]\n",
    "        subinfo = sample.split('_')\n",
    "\n",
    "        df['sample'] = [sample for i in df.index]\n",
    "\n",
    "        if sample_info:\n",
    "            sdict = dict(zip(sample_info, subinfo))\n",
    "        else:\n",
    "            sdict = dict(zip(['s'+i for i,v in enumerate(subinfo)], \n",
    "                             subinfo))\n",
    "\n",
    "        for col, info in sdict.items():\n",
    "            df[col] = [info for i in df.index]\n",
    "\n",
    "        #  Add blanks\n",
    "        if average_blanks:\n",
    "            avblank = np.mean(df[df['Well'].isin(water)]['590'])\n",
    "            df['blanked_590'] = df['590'] - avblank\n",
    "        else:\n",
    "            df['column'] = [i[1:] for i in df['Well']]\n",
    "            techreps = np.append(np.arange(1,12,4),13)\n",
    "            for i, w in enumerate(water):\n",
    "                blank = df.set_index('Well').loc[w,'590']\n",
    "                cols = [str(i) for i in range(techreps[i],techreps[i+1])]\n",
    "                subdf = df[df['column'].isin(cols)].copy()\n",
    "                inds = subdf.index\n",
    "                df.loc[inds,'blanked_590'] = subdf['590'] - blank\n",
    "            df = df.drop('column', axis=1)\n",
    "        # Zero negatives\n",
    "        if zero_negatives:\n",
    "            df['blanked_590'] = df['blanked_590'].clip(0)\n",
    "        else:\n",
    "            pass\n",
    "                \n",
    "        df_ls.append(df)\n",
    "\n",
    "    # Concatenate, reindex\n",
    "    df_all = pd.concat(df_ls)\n",
    "    df_all.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Add hours column\n",
    "    df_all['hours'] = [int(i[:-1]) for i in df_all['timepoint']]\n",
    "\n",
    "    return df_all\n",
    "\n",
    "def ecoplate_importer(fdir,\n",
    "                      sheet_json,\n",
    "                      sample_info,\n",
    "                      metab_json,\n",
    "                      average_blanks=False,\n",
    "                      zero_negatives=True,\n",
    "                      plate_flip=None):\n",
    "    '''\n",
    "    Importer to convert all EcoPlate data files in a folder to a tidy dataframe.\n",
    "\n",
    "    Params\n",
    "    ______\n",
    "\n",
    "    fdir : str\n",
    "        Path to the directory containing EcoPlate Excel files. The importer will attempt\n",
    "        to import all Excel files in the folder. See \"onefile_importer()\" for additional\n",
    "        details.\n",
    "\n",
    "    sheet_json : str\n",
    "        Path to a JSON file containing sample information for each sheet. The keys of \n",
    "        the JSON should be the sheet names (e.g., \"Plate 1 - Sheet1\") and the values\n",
    "        should be the sample name (e.g., \"25D_W_1\"). If the sample name contains\n",
    "        multiple pieces of relevant information (in this case condition, water/larvae,\n",
    "        and replicate), the pieces should be separated by underscores. There are no limits\n",
    "        on the amount of information you can store in the sample name, but all sample names\n",
    "        must contain the same number of underscores.\n",
    "\n",
    "    sample_info : tuple or None\n",
    "        A tuple containing the desired column names for infomation derived from sample\n",
    "        names. For samples with the format \"25D_W_1\", sample_info might be (\"diapause\",\n",
    "        \"water\",\"replicate\"). If None, the columns will be named \"s1\", \"s2\", etc.\n",
    "\n",
    "    metab_json : str\n",
    "        Path to a JSON file in which keys are the plate well positions and values are the \n",
    "        metabolites. The JSON provided in the \"resources\" folder of this repo is derived\n",
    "        from this file: \n",
    "        https://www.biolog.com/wp-content/uploads/2023/08/00A-012-Rev-F-EcoPlate-IFU.pdf\n",
    "\n",
    "    average_blanks : Bool\n",
    "        If True, all Water well 590 values will be averaged and used as the blank for the \n",
    "        entire plate. If False, the A1 Water well will be used to blank columns 1-4, A5 \n",
    "        for columns 5-8, and A9 for columns 9-12. Default: False\n",
    "    \n",
    "    zero_negatives : Bool\n",
    "        If True, any blanked 590 absorbance values below zero will instead be set to zero/\n",
    "        If False, negative values will remain negative. Default: True\n",
    "\n",
    "    plate_flip : list or None\n",
    "        A list of timepoints (in the format \"24h\") for which plates should be flipped.\n",
    "        Function does not currently support plates with multiple orientations in the \n",
    "        same Excel file. Default: None.\n",
    "\n",
    "    Output\n",
    "    ______\n",
    "\n",
    "    A Pandas DataFrame containing columns for well, metabolite, raw 590 value, blanked\n",
    "    590 value, and any sample information for all files in the directory.\n",
    "    \n",
    "    '''\n",
    "    # Extract files\n",
    "    files = [i for i in os.listdir(fdir) if '.xlsx' in i]\n",
    "    files = [i for i in files if '~' not in i]\n",
    "\n",
    "    # Use onefile_importer() to get data for each file\n",
    "    df_ls = []\n",
    "    for f in files:\n",
    "        if not a:\n",
    "            pf = False\n",
    "        elif f.split('_')[0] in a:\n",
    "            pf = True\n",
    "        else:\n",
    "            pf = False\n",
    "            \n",
    "        df_ls.append(onefile_importer(fdir+f,\n",
    "                                       sheet_json,\n",
    "                                       sample_info,\n",
    "                                       metab_json,\n",
    "                                       average_blanks=False,\n",
    "                                       zero_negatives=True,\n",
    "                                       plate_flip=False))\n",
    "\n",
    "    return pd.concat(df_ls)\n",
    "\n",
    "def averager(data,\n",
    "             by,\n",
    "             to_avg,\n",
    "             keep = None,\n",
    "             stdev = True,):\n",
    "    '''\n",
    "    A function to average imported EcoPlate data.\n",
    "\n",
    "    Params\n",
    "    ______\n",
    "\n",
    "    data : a Pandas DataFrame\n",
    "        The output of ecoplate_importer()\n",
    "\n",
    "    by : str or list\n",
    "        The columns that should be used to group entries for averaging.\n",
    "        If a string, only that column will be used to group samples. If \n",
    "        a tuple or list, the union of the columns will be used for grouping.\n",
    "        For example, if ['metab', 'sample'] is supplied for 'by', the values\n",
    "        will be averaged by df['metab'] + df['sample']. An example value for\n",
    "        this combination would be 'Water25EW1'.\n",
    "\n",
    "    to_avg : str, tuple, or list\n",
    "        Any values that should be averaged for the groupings identified by \n",
    "        'by'. Should be '590', 'blanked_590', or ['590', 'blanked_590'].\n",
    "\n",
    "    keep : str, list, or None\n",
    "        Any columns that are identical for all entries in the groups\n",
    "        generated by 'by' and should be kept in the output dataframe.\n",
    "        Usually this will be the 'hours' column, but could be others\n",
    "        added to the dataframe after importing. Default: None.\n",
    "\n",
    "    stdev : Bool\n",
    "        Whether to make a column for standard deviation as well as \n",
    "        arithmetic mean. Default: True.\n",
    "    '''\n",
    "\n",
    "    # By can be one or more entries; handle that\n",
    "    if type(by) != str:\n",
    "        data[''.join(by)] = data[by].agg(''.join, axis=1)\n",
    "        cols = by\n",
    "        by = ''.join(by)\n",
    "    else:\n",
    "        cols = [by]\n",
    "\n",
    "    # Keep is any information that is the same among all averaged samples, \n",
    "    # should not be included in the filtering to average, but should be retained\n",
    "    # in the final output\n",
    "    if keep:\n",
    "        if type(keep) == str:\n",
    "            cols.append(keep)\n",
    "        else:\n",
    "            cols += keep\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    # Make a list to hold all the data. Iterate through all unique \"by\"\n",
    "    # values and average desired values\n",
    "    rows = []\n",
    "    for b in set(data[by]):\n",
    "        subdf = data[data[by] == b]\n",
    "        # One or more values can be averaged \n",
    "        if type(to_avg) == str:\n",
    "            avg = [np.mean(subdf[to_avg])]\n",
    "            if stdev:\n",
    "                avg.append(np.std(subdf[to_avg]))\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            avg = [np.mean(subdf[a]) for a in to_avg]\n",
    "            if stdev:\n",
    "                avg += [np.mean(subdf[a]) for a in to_avg]\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        out = [subdf.iloc[0][c] for c in cols] + avg\n",
    "        rows.append(tuple(out))\n",
    "\n",
    "    # Handle column names for averaging\n",
    "    if type(to_avg) == str:\n",
    "        cols.append(to_avg+'_mean')\n",
    "        if stdev:\n",
    "            cols.append(to_avg+'_std')\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        cols += [a+'_mean' for a in to_avg]\n",
    "        if stdev:\n",
    "            cols += [a+'_std' for a in to_avg]\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    return pd.DataFrame(rows, columns=cols) \n",
    "\n",
    "def integrator(av_df,\n",
    "               by,\n",
    "               xval,\n",
    "               yval):\n",
    "    '''\n",
    "    Function to integrate average EcoPlate data over time. Calculates the area\n",
    "    using the trapezoidal rule.\n",
    "\n",
    "    Params\n",
    "    ______\n",
    "\n",
    "    av_df : a Pandas DataFrame\n",
    "        The output of averager.\n",
    "\n",
    "    by : str or list\n",
    "        Which column(s) to group samples for integration. Each group\n",
    "        should only have one average value for each timepoint.\n",
    "        Typically should be the \"by\" from averager without \"timepoint\".\n",
    "\n",
    "    xval : str\n",
    "        Which column to use as x-values. Typically \"hours\".\n",
    "\n",
    "    yval : str\n",
    "        Which column to use as y-values. Typically \"blanked_590_mean\".\n",
    "        \n",
    "    '''\n",
    "\n",
    "    # By can be one or more entries; handle that\n",
    "    if type(by) != str:\n",
    "        av_df[''.join(by)] = av_df[by].agg(''.join, axis=1)\n",
    "        cols = by\n",
    "        by = ''.join(by)\n",
    "    else:\n",
    "        cols = [by]\n",
    "\n",
    "    # Integrate\n",
    "    rows = []\n",
    "    for b in set(av_df[by]):\n",
    "        subdf = av_df[av_df[by] == b].copy()\n",
    "        subdf = subdf.sort_values(xval, ascending=True).reset_index(drop=True)\n",
    "        ind_areas = []\n",
    "        for i in subdf.index[:-1]:\n",
    "            h = subdf.loc[i+1,xval] - subdf.loc[i,xval]\n",
    "            a = subdf.loc[i,yval]\n",
    "            b = subdf.loc[i+1,yval]\n",
    "            ind_areas.append(h * (a+b) / 2)\n",
    "        area = np.sum(ind_areas)\n",
    "        out = [subdf.loc[0][c] for c in cols] + [area]\n",
    "        rows.append(out)\n",
    "\n",
    "    cols.append('trapezoid_integration')\n",
    "    return pd.DataFrame(rows,columns=cols)\n",
    "\n",
    "def metabolite_pca(int_df,\n",
    "                   cols='metab',\n",
    "                   index='sample',\n",
    "                   n_components=2, \n",
    "                   scale_data=True):\n",
    "    \"\"\"\n",
    "    Perform PCA on metabolite data and return results in long format.\n",
    "    Written with assistance of Claude.ai.\n",
    "    \n",
    "    Params\n",
    "    ______\n",
    "    df : Pandas DataFrame \n",
    "        The output of integrator.\n",
    "\n",
    "    cols : str\n",
    "        Column in integrator dataframe to use as columns for PCA dataframe.\n",
    "        Default: 'metab'.\n",
    "\n",
    "    index : str\n",
    "        Column in integrator dataframe to use as index for PCA dataframe.\n",
    "        Default: 'sample'.\n",
    "        \n",
    "    n_components : int\n",
    "        Number of principal components. Default: 2.\n",
    "        \n",
    "    scale_data : Bool \n",
    "        If True, data will be standardized using the formula\n",
    "        z = (x - u) / s, where x is the original value, u is the\n",
    "        mean of the data, and s is the standard deviation of the data.\n",
    "        Essentially, this is required to make the data roughly Gaussian.\n",
    "        Default: True.\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame with columns: metabolite, sample, PC1, PC2, ...\n",
    "    \"\"\"\n",
    "    # Reshape dataframe and remove water (should be zero for all)\n",
    "    keep = [cols,index,'trapezoid_integration']\n",
    "    df = int_df.loc[:,keep]\n",
    "    df = df.pivot(columns=cols,index=index,values='trapezoid_integration')\n",
    "    df = df.drop('Water',axis=1)\n",
    "    \n",
    "    # Standardize the data\n",
    "    if scale_data:\n",
    "        scaler = StandardScaler()\n",
    "        df_scaled = pd.DataFrame(\n",
    "            scaler.fit_transform(df),\n",
    "            index=df.index,\n",
    "            columns=df.columns\n",
    "        )\n",
    "    else:\n",
    "        df_scaled = df.copy()\n",
    "    \n",
    "    # Perform PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca_result = pca.fit_transform(df_scaled)\n",
    "    \n",
    "    # Create DataFrame with PC scores\n",
    "    pc_columns = [f'PC{i+1}' for i in range(n_components)]\n",
    "    pca_df = pd.DataFrame(\n",
    "        pca_result,\n",
    "        index=df.index,  # samples\n",
    "        columns=pc_columns\n",
    "    )\n",
    "    \n",
    "    # Get PCA loadings (how much each metabolite contributes to each PC)\n",
    "    loadings = pd.DataFrame(\n",
    "        pca.components_.T,\n",
    "        index=df.columns,  # metabolites\n",
    "        columns=pc_columns\n",
    "    )\n",
    "    \n",
    "    # Create the desired long format\n",
    "    # For each metabolite, we'll include its loading values as the PC scores\n",
    "    result_data = []\n",
    "    \n",
    "    for metabolite in df.columns:\n",
    "        for sample in df.index:\n",
    "            row_data = {\n",
    "                'metabolite': metabolite,\n",
    "                'sample': sample\n",
    "            }\n",
    "            # Add PC scores for this sample\n",
    "            for pc in pc_columns:\n",
    "                row_data[pc] = pca_df.loc[sample, pc]\n",
    "            \n",
    "            result_data.append(row_data)\n",
    "    \n",
    "    result_df = pd.DataFrame(result_data)\n",
    "    \n",
    "    # Print PCA summary\n",
    "    print(f\"\\nPCA Results Summary:\")\n",
    "    print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "    print(f\"Total explained variance: {pca.explained_variance_ratio_.sum():.3f}\")\n",
    "    \n",
    "    return result_df, pca, loadings.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe37d049-9e1f-4e83-8bd3-866bebd78334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Well</th>\n",
       "      <th>590</th>\n",
       "      <th>metab</th>\n",
       "      <th>timepoint</th>\n",
       "      <th>sample</th>\n",
       "      <th>diapause</th>\n",
       "      <th>specimen</th>\n",
       "      <th>rep</th>\n",
       "      <th>blanked_590</th>\n",
       "      <th>hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1</td>\n",
       "      <td>0.310</td>\n",
       "      <td>Water</td>\n",
       "      <td>24h</td>\n",
       "      <td>4_L_1</td>\n",
       "      <td>4</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A5</td>\n",
       "      <td>0.271</td>\n",
       "      <td>Water</td>\n",
       "      <td>24h</td>\n",
       "      <td>4_L_1</td>\n",
       "      <td>4</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A9</td>\n",
       "      <td>0.334</td>\n",
       "      <td>Water</td>\n",
       "      <td>24h</td>\n",
       "      <td>4_L_1</td>\n",
       "      <td>4</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2</td>\n",
       "      <td>0.206</td>\n",
       "      <td>β-Methyl-D-Glucoside</td>\n",
       "      <td>24h</td>\n",
       "      <td>4_L_1</td>\n",
       "      <td>4</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A6</td>\n",
       "      <td>0.221</td>\n",
       "      <td>β-Methyl-D-Glucoside</td>\n",
       "      <td>24h</td>\n",
       "      <td>4_L_1</td>\n",
       "      <td>4</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Well    590                 metab timepoint sample diapause specimen rep  \\\n",
       "0   A1  0.310                 Water       24h  4_L_1        4        L   1   \n",
       "1   A5  0.271                 Water       24h  4_L_1        4        L   1   \n",
       "2   A9  0.334                 Water       24h  4_L_1        4        L   1   \n",
       "3   A2  0.206  β-Methyl-D-Glucoside       24h  4_L_1        4        L   1   \n",
       "4   A6  0.221  β-Methyl-D-Glucoside       24h  4_L_1        4        L   1   \n",
       "\n",
       "   blanked_590  hours  \n",
       "0          0.0     24  \n",
       "1          0.0     24  \n",
       "2          0.0     24  \n",
       "3          0.0     24  \n",
       "4          0.0     24  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = ecoplate_importer('exampleData/',\n",
    "                       'exampleData/plateIDs.json',\n",
    "                       ['diapause','specimen','rep'],\n",
    "                       'resources/ecoPlate.json',\n",
    "                       average_blanks=False,\n",
    "                       zero_negatives=True,\n",
    "                       plate_flip=['60h'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adc2615d-881d-4c0b-8d87-0b394ef43254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metab</th>\n",
       "      <th>timepoint</th>\n",
       "      <th>diapause</th>\n",
       "      <th>specimen</th>\n",
       "      <th>rep</th>\n",
       "      <th>sample</th>\n",
       "      <th>hours</th>\n",
       "      <th>blanked_590_mean</th>\n",
       "      <th>blanked_590_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Putrescine</td>\n",
       "      <td>60h</td>\n",
       "      <td>4</td>\n",
       "      <td>L</td>\n",
       "      <td>3</td>\n",
       "      <td>4_L_3</td>\n",
       "      <td>60</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D-Galacturonic Acid</td>\n",
       "      <td>24h</td>\n",
       "      <td>ND</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>ND_L_1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.293000</td>\n",
       "      <td>0.052122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Itaconic Acid</td>\n",
       "      <td>24h</td>\n",
       "      <td>25E</td>\n",
       "      <td>W</td>\n",
       "      <td>3</td>\n",
       "      <td>25E_W_3</td>\n",
       "      <td>24</td>\n",
       "      <td>0.030333</td>\n",
       "      <td>0.026712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Putrescine</td>\n",
       "      <td>24h</td>\n",
       "      <td>25D</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "      <td>25D_W_1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.042333</td>\n",
       "      <td>0.049641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2-Hydroxy Benzoic Acid</td>\n",
       "      <td>60h</td>\n",
       "      <td>ND</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>ND_L_1</td>\n",
       "      <td>60</td>\n",
       "      <td>0.009333</td>\n",
       "      <td>0.008219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    metab timepoint diapause specimen rep   sample  hours  \\\n",
       "0              Putrescine       60h        4        L   3    4_L_3     60   \n",
       "1     D-Galacturonic Acid       24h       ND        L   1   ND_L_1     24   \n",
       "2           Itaconic Acid       24h      25E        W   3  25E_W_3     24   \n",
       "3              Putrescine       24h      25D        W   1  25D_W_1     24   \n",
       "4  2-Hydroxy Benzoic Acid       60h       ND        L   1   ND_L_1     60   \n",
       "\n",
       "   blanked_590_mean  blanked_590_std  \n",
       "0          0.000000         0.000000  \n",
       "1          0.293000         0.052122  \n",
       "2          0.030333         0.026712  \n",
       "3          0.042333         0.049641  \n",
       "4          0.009333         0.008219  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "av_df = averager(df,\n",
    "                 ['metab','timepoint','diapause','specimen','rep'],\n",
    "                 'blanked_590',\n",
    "                 keep=['sample','hours'])\n",
    "\n",
    "av_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bf66709-072e-4c97-9621-9bb29a3c94fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metab</th>\n",
       "      <th>sample</th>\n",
       "      <th>trapezoid_integration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D-Galacturonic Acid</td>\n",
       "      <td>4_L_2</td>\n",
       "      <td>33.852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D-Glucosaminic Acid</td>\n",
       "      <td>ND_W_2</td>\n",
       "      <td>0.852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>α-D-Lactose</td>\n",
       "      <td>25D_L_1</td>\n",
       "      <td>0.444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>β-Hydroxy-Glycyl-L-Glutamic Acid</td>\n",
       "      <td>25D_W_2</td>\n",
       "      <td>1.476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L-Phenylalanine</td>\n",
       "      <td>25D_L_2</td>\n",
       "      <td>1.080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              metab   sample  trapezoid_integration\n",
       "0               D-Galacturonic Acid    4_L_2                 33.852\n",
       "1               D-Glucosaminic Acid   ND_W_2                  0.852\n",
       "2                       α-D-Lactose  25D_L_1                  0.444\n",
       "3  β-Hydroxy-Glycyl-L-Glutamic Acid  25D_W_2                  1.476\n",
       "4                   L-Phenylalanine  25D_L_2                  1.080"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_df = integrator(av_df,\n",
    "                  ['metab','sample'],\n",
    "                  'hours',\n",
    "                  'blanked_590_mean')\n",
    "\n",
    "int_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "845a8dc1-4214-4bae-b223-f7f426770925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PCA Results Summary:\n",
      "Explained variance ratio: [0.47498323 0.17154261]\n",
      "Total explained variance: 0.647\n"
     ]
    }
   ],
   "source": [
    "result_df, pca, loadings = metabolite_pca(int_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4893bea5-57ba-42db-95a1-535646591b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metab</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2-Hydroxy Benzoic Acid</th>\n",
       "      <td>0.050</td>\n",
       "      <td>-0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-Hydroxy Benzoic Acid</th>\n",
       "      <td>-0.128</td>\n",
       "      <td>0.158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D,L-α-Glycerol Phosphate</th>\n",
       "      <td>0.204</td>\n",
       "      <td>0.217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D-Cellobiose</th>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D-Galactonic Acid γ-Lactone</th>\n",
       "      <td>-0.200</td>\n",
       "      <td>0.217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               PC1    PC2\n",
       "metab                                    \n",
       "2-Hydroxy Benzoic Acid       0.050 -0.037\n",
       "4-Hydroxy Benzoic Acid      -0.128  0.158\n",
       "D,L-α-Glycerol Phosphate     0.204  0.217\n",
       "D-Cellobiose                -0.137  0.033\n",
       "D-Galactonic Acid γ-Lactone -0.200  0.217"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2df2aaa8-1c51-4021-b0b9-00f6a90e197b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output/test.txt','w') as f:\n",
    "    f.write(f\"PCA Results Summary:\\n\")\n",
    "    f.write(f\"Explained variance ratio: {pca.explained_variance_ratio_}\\n\")\n",
    "    f.write(f\"Total explained variance: {pca.explained_variance_ratio_.sum():.3f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30e6077-e85e-44fa-923c-6ba8775667a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
